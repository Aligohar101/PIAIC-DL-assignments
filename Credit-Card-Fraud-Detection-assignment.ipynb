{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"},"colab":{"name":"Credit-Card-Fraud-Detection-assignment.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"Qg0V0wzAo280","executionInfo":{"status":"ok","timestamp":1617452304486,"user_tz":-300,"elapsed":811,"user":{"displayName":"Aligohar Khokhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCbikLe5dCIFAg2TZGgZ4T1ynawIsMZqR168ZfXA=s64","userId":"18174892672448340788"}}},"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from keras import models,layers\n","from keras import regularizers\n","from sklearn.model_selection import train_test_split\n"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":426},"id":"vZAEEk8Oqv6T","executionInfo":{"status":"ok","timestamp":1617452309613,"user_tz":-300,"elapsed":1109,"user":{"displayName":"Aligohar Khokhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCbikLe5dCIFAg2TZGgZ4T1ynawIsMZqR168ZfXA=s64","userId":"18174892672448340788"}},"outputId":"e2843e60-957d-4e9f-8781-a4d19af19304"},"source":["df = pd.read_csv('./creditcard.csv')\n","df"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Time</th>\n","      <th>V1</th>\n","      <th>V2</th>\n","      <th>V3</th>\n","      <th>V4</th>\n","      <th>V5</th>\n","      <th>V6</th>\n","      <th>V7</th>\n","      <th>V8</th>\n","      <th>V9</th>\n","      <th>V10</th>\n","      <th>V11</th>\n","      <th>V12</th>\n","      <th>V13</th>\n","      <th>V14</th>\n","      <th>V15</th>\n","      <th>V16</th>\n","      <th>V17</th>\n","      <th>V18</th>\n","      <th>V19</th>\n","      <th>V20</th>\n","      <th>V21</th>\n","      <th>V22</th>\n","      <th>V23</th>\n","      <th>V24</th>\n","      <th>V25</th>\n","      <th>V26</th>\n","      <th>V27</th>\n","      <th>V28</th>\n","      <th>Amount</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>-1.359807</td>\n","      <td>-0.072781</td>\n","      <td>2.536347</td>\n","      <td>1.378155</td>\n","      <td>-0.338321</td>\n","      <td>0.462388</td>\n","      <td>0.239599</td>\n","      <td>0.098698</td>\n","      <td>0.363787</td>\n","      <td>0.090794</td>\n","      <td>-0.551600</td>\n","      <td>-0.617801</td>\n","      <td>-0.991390</td>\n","      <td>-0.311169</td>\n","      <td>1.468177</td>\n","      <td>-0.470401</td>\n","      <td>0.207971</td>\n","      <td>0.025791</td>\n","      <td>0.403993</td>\n","      <td>0.251412</td>\n","      <td>-0.018307</td>\n","      <td>0.277838</td>\n","      <td>-0.110474</td>\n","      <td>0.066928</td>\n","      <td>0.128539</td>\n","      <td>-0.189115</td>\n","      <td>0.133558</td>\n","      <td>-0.021053</td>\n","      <td>149.62</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1.191857</td>\n","      <td>0.266151</td>\n","      <td>0.166480</td>\n","      <td>0.448154</td>\n","      <td>0.060018</td>\n","      <td>-0.082361</td>\n","      <td>-0.078803</td>\n","      <td>0.085102</td>\n","      <td>-0.255425</td>\n","      <td>-0.166974</td>\n","      <td>1.612727</td>\n","      <td>1.065235</td>\n","      <td>0.489095</td>\n","      <td>-0.143772</td>\n","      <td>0.635558</td>\n","      <td>0.463917</td>\n","      <td>-0.114805</td>\n","      <td>-0.183361</td>\n","      <td>-0.145783</td>\n","      <td>-0.069083</td>\n","      <td>-0.225775</td>\n","      <td>-0.638672</td>\n","      <td>0.101288</td>\n","      <td>-0.339846</td>\n","      <td>0.167170</td>\n","      <td>0.125895</td>\n","      <td>-0.008983</td>\n","      <td>0.014724</td>\n","      <td>2.69</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>-1.358354</td>\n","      <td>-1.340163</td>\n","      <td>1.773209</td>\n","      <td>0.379780</td>\n","      <td>-0.503198</td>\n","      <td>1.800499</td>\n","      <td>0.791461</td>\n","      <td>0.247676</td>\n","      <td>-1.514654</td>\n","      <td>0.207643</td>\n","      <td>0.624501</td>\n","      <td>0.066084</td>\n","      <td>0.717293</td>\n","      <td>-0.165946</td>\n","      <td>2.345865</td>\n","      <td>-2.890083</td>\n","      <td>1.109969</td>\n","      <td>-0.121359</td>\n","      <td>-2.261857</td>\n","      <td>0.524980</td>\n","      <td>0.247998</td>\n","      <td>0.771679</td>\n","      <td>0.909412</td>\n","      <td>-0.689281</td>\n","      <td>-0.327642</td>\n","      <td>-0.139097</td>\n","      <td>-0.055353</td>\n","      <td>-0.059752</td>\n","      <td>378.66</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>-0.966272</td>\n","      <td>-0.185226</td>\n","      <td>1.792993</td>\n","      <td>-0.863291</td>\n","      <td>-0.010309</td>\n","      <td>1.247203</td>\n","      <td>0.237609</td>\n","      <td>0.377436</td>\n","      <td>-1.387024</td>\n","      <td>-0.054952</td>\n","      <td>-0.226487</td>\n","      <td>0.178228</td>\n","      <td>0.507757</td>\n","      <td>-0.287924</td>\n","      <td>-0.631418</td>\n","      <td>-1.059647</td>\n","      <td>-0.684093</td>\n","      <td>1.965775</td>\n","      <td>-1.232622</td>\n","      <td>-0.208038</td>\n","      <td>-0.108300</td>\n","      <td>0.005274</td>\n","      <td>-0.190321</td>\n","      <td>-1.175575</td>\n","      <td>0.647376</td>\n","      <td>-0.221929</td>\n","      <td>0.062723</td>\n","      <td>0.061458</td>\n","      <td>123.50</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>-1.158233</td>\n","      <td>0.877737</td>\n","      <td>1.548718</td>\n","      <td>0.403034</td>\n","      <td>-0.407193</td>\n","      <td>0.095921</td>\n","      <td>0.592941</td>\n","      <td>-0.270533</td>\n","      <td>0.817739</td>\n","      <td>0.753074</td>\n","      <td>-0.822843</td>\n","      <td>0.538196</td>\n","      <td>1.345852</td>\n","      <td>-1.119670</td>\n","      <td>0.175121</td>\n","      <td>-0.451449</td>\n","      <td>-0.237033</td>\n","      <td>-0.038195</td>\n","      <td>0.803487</td>\n","      <td>0.408542</td>\n","      <td>-0.009431</td>\n","      <td>0.798278</td>\n","      <td>-0.137458</td>\n","      <td>0.141267</td>\n","      <td>-0.206010</td>\n","      <td>0.502292</td>\n","      <td>0.219422</td>\n","      <td>0.215153</td>\n","      <td>69.99</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4656</th>\n","      <td>4046</td>\n","      <td>-1.419157</td>\n","      <td>1.751823</td>\n","      <td>0.871490</td>\n","      <td>0.033815</td>\n","      <td>-0.374373</td>\n","      <td>-0.166273</td>\n","      <td>-0.248420</td>\n","      <td>0.966657</td>\n","      <td>0.390515</td>\n","      <td>-0.715362</td>\n","      <td>2.297797</td>\n","      <td>-1.130493</td>\n","      <td>2.297093</td>\n","      <td>2.243270</td>\n","      <td>-0.464764</td>\n","      <td>0.271479</td>\n","      <td>0.659115</td>\n","      <td>-0.046540</td>\n","      <td>-0.301317</td>\n","      <td>-0.022924</td>\n","      <td>-0.239606</td>\n","      <td>-0.551645</td>\n","      <td>0.109464</td>\n","      <td>-0.049862</td>\n","      <td>-0.202307</td>\n","      <td>0.052414</td>\n","      <td>0.119387</td>\n","      <td>0.026361</td>\n","      <td>8.99</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4657</th>\n","      <td>4048</td>\n","      <td>-1.619060</td>\n","      <td>0.687492</td>\n","      <td>2.283881</td>\n","      <td>0.135850</td>\n","      <td>-0.348660</td>\n","      <td>2.173278</td>\n","      <td>-0.637450</td>\n","      <td>1.274966</td>\n","      <td>1.318315</td>\n","      <td>-1.127718</td>\n","      <td>2.634005</td>\n","      <td>-1.659902</td>\n","      <td>0.535918</td>\n","      <td>1.684505</td>\n","      <td>-0.214868</td>\n","      <td>-0.960104</td>\n","      <td>1.851847</td>\n","      <td>-1.146547</td>\n","      <td>-1.351567</td>\n","      <td>-0.235185</td>\n","      <td>-0.018311</td>\n","      <td>0.387256</td>\n","      <td>0.109870</td>\n","      <td>-0.870232</td>\n","      <td>-0.150190</td>\n","      <td>0.425930</td>\n","      <td>0.113039</td>\n","      <td>0.013690</td>\n","      <td>60.90</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4658</th>\n","      <td>4049</td>\n","      <td>-0.677034</td>\n","      <td>-0.031392</td>\n","      <td>2.591247</td>\n","      <td>-0.756693</td>\n","      <td>-0.266149</td>\n","      <td>0.364260</td>\n","      <td>0.201486</td>\n","      <td>0.074833</td>\n","      <td>1.780884</td>\n","      <td>-1.245756</td>\n","      <td>2.193685</td>\n","      <td>-1.196707</td>\n","      <td>1.809113</td>\n","      <td>0.648516</td>\n","      <td>-2.222445</td>\n","      <td>-0.161459</td>\n","      <td>0.541773</td>\n","      <td>-0.385646</td>\n","      <td>-0.612098</td>\n","      <td>0.079597</td>\n","      <td>-0.230477</td>\n","      <td>-0.203616</td>\n","      <td>0.077837</td>\n","      <td>0.224800</td>\n","      <td>-0.213579</td>\n","      <td>0.713807</td>\n","      <td>-0.246913</td>\n","      <td>-0.229547</td>\n","      <td>69.34</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4659</th>\n","      <td>4053</td>\n","      <td>1.104345</td>\n","      <td>-0.531407</td>\n","      <td>1.088893</td>\n","      <td>0.307874</td>\n","      <td>-1.049402</td>\n","      <td>0.166874</td>\n","      <td>-0.869630</td>\n","      <td>0.193954</td>\n","      <td>2.418299</td>\n","      <td>-0.641927</td>\n","      <td>1.363010</td>\n","      <td>-1.948131</td>\n","      <td>0.472848</td>\n","      <td>1.289907</td>\n","      <td>-1.587233</td>\n","      <td>0.203006</td>\n","      <td>0.570556</td>\n","      <td>0.385682</td>\n","      <td>0.670404</td>\n","      <td>-0.076194</td>\n","      <td>-0.339354</td>\n","      <td>-0.664476</td>\n","      <td>0.011053</td>\n","      <td>-0.004883</td>\n","      <td>0.072565</td>\n","      <td>0.905579</td>\n","      <td>-0.080857</td>\n","      <td>0.000137</td>\n","      <td>55.07</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4660</th>\n","      <td>4058</td>\n","      <td>-1.341427</td>\n","      <td>-0.100753</td>\n","      <td>3.760965</td>\n","      <td>3.576198</td>\n","      <td>-0.964253</td>\n","      <td>2.371730</td>\n","      <td>0.472248</td>\n","      <td>-0.357988</td>\n","      <td>2.067429</td>\n","      <td>0.656033</td>\n","      <td>0.075427</td>\n","      <td>-2.101231</td>\n","      <td>2.663117</td>\n","      <td>-0.796656</td>\n","      <td>-1.500703</td>\n","      <td>-1.145182</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4661 rows Ã— 31 columns</p>\n","</div>"],"text/plain":["      Time        V1        V2        V3  ...       V27       V28  Amount  Class\n","0        0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62    0.0\n","1        0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69    0.0\n","2        1 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66    0.0\n","3        1 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50    0.0\n","4        2 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99    0.0\n","...    ...       ...       ...       ...  ...       ...       ...     ...    ...\n","4656  4046 -1.419157  1.751823  0.871490  ...  0.119387  0.026361    8.99    0.0\n","4657  4048 -1.619060  0.687492  2.283881  ...  0.113039  0.013690   60.90    0.0\n","4658  4049 -0.677034 -0.031392  2.591247  ... -0.246913 -0.229547   69.34    0.0\n","4659  4053  1.104345 -0.531407  1.088893  ... -0.080857  0.000137   55.07    0.0\n","4660  4058 -1.341427 -0.100753  3.760965  ...       NaN       NaN     NaN    NaN\n","\n","[4661 rows x 31 columns]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"9kOptdy-o286","executionInfo":{"status":"ok","timestamp":1617452310013,"user_tz":-300,"elapsed":654,"user":{"displayName":"Aligohar Khokhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCbikLe5dCIFAg2TZGgZ4T1ynawIsMZqR168ZfXA=s64","userId":"18174892672448340788"}}},"source":["non_fraud=df[df[\"Class\"]==0]\n","fraud = df[df[\"Class\"]==1]\n","non_fraud=non_fraud.sample(3*fraud.shape[0])\n","data = fraud.append(non_fraud, ignore_index=True)\n","\n","x_data= data.drop(columns=\"Class\", axis=0)\n","label = data[\"Class\"]"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"uSS6_rCXo286","executionInfo":{"status":"ok","timestamp":1617452311368,"user_tz":-300,"elapsed":984,"user":{"displayName":"Aligohar Khokhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCbikLe5dCIFAg2TZGgZ4T1ynawIsMZqR168ZfXA=s64","userId":"18174892672448340788"}}},"source":["train_data, test_data, train_labels, test_labels=train_test_split(x_data, label, test_size=0.3, random_state=1, stratify = label)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"U_WX23U2o287","executionInfo":{"status":"ok","timestamp":1617452311760,"user_tz":-300,"elapsed":678,"user":{"displayName":"Aligohar Khokhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCbikLe5dCIFAg2TZGgZ4T1ynawIsMZqR168ZfXA=s64","userId":"18174892672448340788"}}},"source":["train_mean = train_data.mean(axis=0)\n","train_data -= train_mean\n","train_std = train_data.std(axis=0)\n","train_data /= train_std\n","test_data -= train_mean\n","test_data /= train_std"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"OSx6wIy6o287","executionInfo":{"status":"ok","timestamp":1617452313047,"user_tz":-300,"elapsed":1071,"user":{"displayName":"Aligohar Khokhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCbikLe5dCIFAg2TZGgZ4T1ynawIsMZqR168ZfXA=s64","userId":"18174892672448340788"}}},"source":["model = models.Sequential()\n","model.add(layers.Dense(20, activation='relu',kernel_regularizer=regularizers.l2(0.001), input_shape=(train_data.shape[1],)))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(10, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(8, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(6, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(1, activation='sigmoid'))"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"hnB-GX3fo288","executionInfo":{"status":"ok","timestamp":1617452313822,"user_tz":-300,"elapsed":878,"user":{"displayName":"Aligohar Khokhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCbikLe5dCIFAg2TZGgZ4T1ynawIsMZqR168ZfXA=s64","userId":"18174892672448340788"}}},"source":["model.compile(loss= 'binary_crossentropy', optimizer= 'rmsprop', metrics=['accuracy'])"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PEjoyq-_o288","executionInfo":{"status":"ok","timestamp":1617452321380,"user_tz":-300,"elapsed":7371,"user":{"displayName":"Aligohar Khokhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCbikLe5dCIFAg2TZGgZ4T1ynawIsMZqR168ZfXA=s64","userId":"18174892672448340788"}},"outputId":"293d7999-ef24-41ec-f872-1c31e4cc35e5"},"source":["model.fit(train_data, train_labels, epochs=100,validation_split = 0.3)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","1/1 [==============================] - 1s 1s/step - loss: 1.0321 - accuracy: 0.3333 - val_loss: 1.0752 - val_accuracy: 0.0000e+00\n","Epoch 2/100\n","1/1 [==============================] - 0s 41ms/step - loss: 0.8223 - accuracy: 0.3333 - val_loss: 1.0677 - val_accuracy: 0.0000e+00\n","Epoch 3/100\n","1/1 [==============================] - 0s 43ms/step - loss: 1.4871 - accuracy: 0.3333 - val_loss: 1.0515 - val_accuracy: 0.0000e+00\n","Epoch 4/100\n","1/1 [==============================] - 0s 46ms/step - loss: 0.9064 - accuracy: 0.3333 - val_loss: 1.0478 - val_accuracy: 0.0000e+00\n","Epoch 5/100\n","1/1 [==============================] - 0s 41ms/step - loss: 0.6302 - accuracy: 0.6667 - val_loss: 1.0464 - val_accuracy: 0.0000e+00\n","Epoch 6/100\n","1/1 [==============================] - 0s 43ms/step - loss: 3.6657 - accuracy: 0.6667 - val_loss: 1.0349 - val_accuracy: 0.0000e+00\n","Epoch 7/100\n","1/1 [==============================] - 0s 45ms/step - loss: 1.2456 - accuracy: 0.3333 - val_loss: 1.0337 - val_accuracy: 0.0000e+00\n","Epoch 8/100\n","1/1 [==============================] - 0s 48ms/step - loss: 0.7918 - accuracy: 0.6667 - val_loss: 1.0321 - val_accuracy: 0.0000e+00\n","Epoch 9/100\n","1/1 [==============================] - 0s 50ms/step - loss: 0.5898 - accuracy: 0.6667 - val_loss: 1.0312 - val_accuracy: 0.0000e+00\n","Epoch 10/100\n","1/1 [==============================] - 0s 37ms/step - loss: 1.0882 - accuracy: 0.3333 - val_loss: 1.0298 - val_accuracy: 0.0000e+00\n","Epoch 11/100\n","1/1 [==============================] - 0s 43ms/step - loss: 1.0063 - accuracy: 0.0000e+00 - val_loss: 1.0241 - val_accuracy: 0.0000e+00\n","Epoch 12/100\n","1/1 [==============================] - 0s 50ms/step - loss: 0.7404 - accuracy: 0.6667 - val_loss: 1.0238 - val_accuracy: 0.0000e+00\n","Epoch 13/100\n","1/1 [==============================] - 0s 40ms/step - loss: 0.7511 - accuracy: 0.6667 - val_loss: 1.0240 - val_accuracy: 0.0000e+00\n","Epoch 14/100\n","1/1 [==============================] - 0s 39ms/step - loss: 0.8114 - accuracy: 0.6667 - val_loss: 1.0213 - val_accuracy: 0.0000e+00\n","Epoch 15/100\n","1/1 [==============================] - 0s 40ms/step - loss: 0.8131 - accuracy: 0.0000e+00 - val_loss: 1.0180 - val_accuracy: 0.0000e+00\n","Epoch 16/100\n","1/1 [==============================] - 0s 46ms/step - loss: 1.4664 - accuracy: 0.3333 - val_loss: 1.0139 - val_accuracy: 0.0000e+00\n","Epoch 17/100\n","1/1 [==============================] - 0s 50ms/step - loss: 0.7393 - accuracy: 0.6667 - val_loss: 1.0136 - val_accuracy: 0.0000e+00\n","Epoch 18/100\n","1/1 [==============================] - 0s 55ms/step - loss: 1.0691 - accuracy: 0.3333 - val_loss: 1.0122 - val_accuracy: 0.5000\n","Epoch 19/100\n","1/1 [==============================] - 0s 45ms/step - loss: 0.7489 - accuracy: 0.6667 - val_loss: 1.0125 - val_accuracy: 0.5000\n","Epoch 20/100\n","1/1 [==============================] - 0s 46ms/step - loss: 0.9048 - accuracy: 0.3333 - val_loss: 1.0089 - val_accuracy: 0.5000\n","Epoch 21/100\n","1/1 [==============================] - 0s 46ms/step - loss: 0.7008 - accuracy: 1.0000 - val_loss: 1.0077 - val_accuracy: 0.5000\n","Epoch 22/100\n","1/1 [==============================] - 0s 50ms/step - loss: 0.7852 - accuracy: 0.3333 - val_loss: 1.0046 - val_accuracy: 0.5000\n","Epoch 23/100\n","1/1 [==============================] - 0s 42ms/step - loss: 2.6481 - accuracy: 0.3333 - val_loss: 0.9926 - val_accuracy: 0.5000\n","Epoch 24/100\n","1/1 [==============================] - 0s 41ms/step - loss: 1.2288 - accuracy: 0.6667 - val_loss: 0.9890 - val_accuracy: 0.5000\n","Epoch 25/100\n","1/1 [==============================] - 0s 48ms/step - loss: 0.7211 - accuracy: 0.6667 - val_loss: 0.9885 - val_accuracy: 0.5000\n","Epoch 26/100\n","1/1 [==============================] - 0s 55ms/step - loss: 0.8339 - accuracy: 0.6667 - val_loss: 0.9873 - val_accuracy: 0.5000\n","Epoch 27/100\n","1/1 [==============================] - 0s 49ms/step - loss: 1.4584 - accuracy: 0.0000e+00 - val_loss: 0.9803 - val_accuracy: 0.5000\n","Epoch 28/100\n","1/1 [==============================] - 0s 47ms/step - loss: 0.6450 - accuracy: 1.0000 - val_loss: 0.9803 - val_accuracy: 0.5000\n","Epoch 29/100\n","1/1 [==============================] - 0s 46ms/step - loss: 1.4905 - accuracy: 0.3333 - val_loss: 0.9763 - val_accuracy: 0.5000\n","Epoch 30/100\n","1/1 [==============================] - 0s 40ms/step - loss: 0.8692 - accuracy: 0.0000e+00 - val_loss: 0.9750 - val_accuracy: 0.5000\n","Epoch 31/100\n","1/1 [==============================] - 0s 48ms/step - loss: 0.7292 - accuracy: 0.6667 - val_loss: 0.9741 - val_accuracy: 0.5000\n","Epoch 32/100\n","1/1 [==============================] - 0s 46ms/step - loss: 0.8851 - accuracy: 0.3333 - val_loss: 0.9730 - val_accuracy: 0.5000\n","Epoch 33/100\n","1/1 [==============================] - 0s 45ms/step - loss: 0.9642 - accuracy: 0.0000e+00 - val_loss: 0.9704 - val_accuracy: 0.5000\n","Epoch 34/100\n","1/1 [==============================] - 0s 42ms/step - loss: 0.7378 - accuracy: 0.6667 - val_loss: 0.9665 - val_accuracy: 0.5000\n","Epoch 35/100\n","1/1 [==============================] - 0s 47ms/step - loss: 0.9980 - accuracy: 0.3333 - val_loss: 0.9616 - val_accuracy: 0.5000\n","Epoch 36/100\n","1/1 [==============================] - 0s 50ms/step - loss: 0.7072 - accuracy: 1.0000 - val_loss: 0.9630 - val_accuracy: 0.5000\n","Epoch 37/100\n","1/1 [==============================] - 0s 43ms/step - loss: 0.9126 - accuracy: 0.3333 - val_loss: 0.9619 - val_accuracy: 0.5000\n","Epoch 38/100\n","1/1 [==============================] - 0s 41ms/step - loss: 0.7140 - accuracy: 0.6667 - val_loss: 0.9615 - val_accuracy: 0.5000\n","Epoch 39/100\n","1/1 [==============================] - 0s 53ms/step - loss: 1.2042 - accuracy: 0.6667 - val_loss: 0.9563 - val_accuracy: 0.5000\n","Epoch 40/100\n","1/1 [==============================] - 0s 53ms/step - loss: 0.7345 - accuracy: 0.6667 - val_loss: 0.9559 - val_accuracy: 0.5000\n","Epoch 41/100\n","1/1 [==============================] - 0s 43ms/step - loss: 0.8264 - accuracy: 0.6667 - val_loss: 0.9548 - val_accuracy: 0.5000\n","Epoch 42/100\n","1/1 [==============================] - 0s 44ms/step - loss: 1.0502 - accuracy: 0.0000e+00 - val_loss: 0.9528 - val_accuracy: 0.5000\n","Epoch 43/100\n","1/1 [==============================] - 0s 45ms/step - loss: 0.5674 - accuracy: 1.0000 - val_loss: 0.9518 - val_accuracy: 0.5000\n","Epoch 44/100\n","1/1 [==============================] - 0s 44ms/step - loss: 0.7719 - accuracy: 0.3333 - val_loss: 0.9487 - val_accuracy: 0.5000\n","Epoch 45/100\n","1/1 [==============================] - 0s 44ms/step - loss: 0.9506 - accuracy: 0.3333 - val_loss: 0.9457 - val_accuracy: 0.5000\n","Epoch 46/100\n","1/1 [==============================] - 0s 48ms/step - loss: 0.7092 - accuracy: 1.0000 - val_loss: 0.9461 - val_accuracy: 0.5000\n","Epoch 47/100\n","1/1 [==============================] - 0s 45ms/step - loss: 0.8446 - accuracy: 0.3333 - val_loss: 0.9458 - val_accuracy: 0.5000\n","Epoch 48/100\n","1/1 [==============================] - 0s 42ms/step - loss: 2.0857 - accuracy: 0.3333 - val_loss: 0.9369 - val_accuracy: 0.5000\n","Epoch 49/100\n","1/1 [==============================] - 0s 46ms/step - loss: 1.1411 - accuracy: 0.0000e+00 - val_loss: 0.9353 - val_accuracy: 0.5000\n","Epoch 50/100\n","1/1 [==============================] - 0s 45ms/step - loss: 0.5937 - accuracy: 1.0000 - val_loss: 0.9354 - val_accuracy: 0.5000\n","Epoch 51/100\n","1/1 [==============================] - 0s 48ms/step - loss: 0.7647 - accuracy: 0.6667 - val_loss: 0.9354 - val_accuracy: 0.5000\n","Epoch 52/100\n","1/1 [==============================] - 0s 47ms/step - loss: 1.5067 - accuracy: 0.3333 - val_loss: 0.9337 - val_accuracy: 0.5000\n","Epoch 53/100\n","1/1 [==============================] - 0s 47ms/step - loss: 0.7460 - accuracy: 0.3333 - val_loss: 0.9308 - val_accuracy: 0.5000\n","Epoch 54/100\n","1/1 [==============================] - 0s 48ms/step - loss: 0.7594 - accuracy: 0.3333 - val_loss: 0.9310 - val_accuracy: 0.5000\n","Epoch 55/100\n","1/1 [==============================] - 0s 50ms/step - loss: 0.8458 - accuracy: 0.3333 - val_loss: 0.9303 - val_accuracy: 0.5000\n","Epoch 56/100\n","1/1 [==============================] - 0s 46ms/step - loss: 0.7311 - accuracy: 0.6667 - val_loss: 0.9302 - val_accuracy: 0.5000\n","Epoch 57/100\n","1/1 [==============================] - 0s 44ms/step - loss: 0.6801 - accuracy: 1.0000 - val_loss: 0.9297 - val_accuracy: 0.5000\n","Epoch 58/100\n","1/1 [==============================] - 0s 43ms/step - loss: 0.7264 - accuracy: 0.6667 - val_loss: 0.9298 - val_accuracy: 0.5000\n","Epoch 59/100\n","1/1 [==============================] - 0s 42ms/step - loss: 0.6751 - accuracy: 1.0000 - val_loss: 0.9314 - val_accuracy: 0.5000\n","Epoch 60/100\n","1/1 [==============================] - 0s 53ms/step - loss: 0.7467 - accuracy: 0.3333 - val_loss: 0.9310 - val_accuracy: 0.5000\n","Epoch 61/100\n","1/1 [==============================] - 0s 54ms/step - loss: 0.6859 - accuracy: 1.0000 - val_loss: 0.9303 - val_accuracy: 0.5000\n","Epoch 62/100\n","1/1 [==============================] - 0s 50ms/step - loss: 0.7208 - accuracy: 0.6667 - val_loss: 0.9317 - val_accuracy: 0.5000\n","Epoch 63/100\n","1/1 [==============================] - 0s 54ms/step - loss: 0.7291 - accuracy: 0.6667 - val_loss: 0.9315 - val_accuracy: 0.5000\n","Epoch 64/100\n","1/1 [==============================] - 0s 44ms/step - loss: 0.5677 - accuracy: 1.0000 - val_loss: 0.9323 - val_accuracy: 0.5000\n","Epoch 65/100\n","1/1 [==============================] - 0s 44ms/step - loss: 0.9409 - accuracy: 0.3333 - val_loss: 0.9291 - val_accuracy: 0.5000\n","Epoch 66/100\n","1/1 [==============================] - 0s 50ms/step - loss: 0.5518 - accuracy: 1.0000 - val_loss: 0.9276 - val_accuracy: 0.5000\n","Epoch 67/100\n","1/1 [==============================] - 0s 48ms/step - loss: 0.7526 - accuracy: 0.3333 - val_loss: 0.9251 - val_accuracy: 0.5000\n","Epoch 68/100\n","1/1 [==============================] - 0s 49ms/step - loss: 0.8739 - accuracy: 0.0000e+00 - val_loss: 0.9255 - val_accuracy: 0.5000\n","Epoch 69/100\n","1/1 [==============================] - 0s 49ms/step - loss: 0.4858 - accuracy: 1.0000 - val_loss: 0.9249 - val_accuracy: 0.5000\n","Epoch 70/100\n","1/1 [==============================] - 0s 50ms/step - loss: 0.8264 - accuracy: 0.6667 - val_loss: 0.9229 - val_accuracy: 0.5000\n","Epoch 71/100\n","1/1 [==============================] - 0s 49ms/step - loss: 0.5190 - accuracy: 0.6667 - val_loss: 0.9217 - val_accuracy: 0.5000\n","Epoch 72/100\n","1/1 [==============================] - 0s 49ms/step - loss: 1.5372 - accuracy: 0.0000e+00 - val_loss: 0.9147 - val_accuracy: 0.5000\n","Epoch 73/100\n","1/1 [==============================] - 0s 47ms/step - loss: 0.7753 - accuracy: 0.3333 - val_loss: 0.9132 - val_accuracy: 0.5000\n","Epoch 74/100\n","1/1 [==============================] - 0s 42ms/step - loss: 0.6788 - accuracy: 0.3333 - val_loss: 0.9094 - val_accuracy: 0.5000\n","Epoch 75/100\n","1/1 [==============================] - 0s 51ms/step - loss: 0.7132 - accuracy: 0.3333 - val_loss: 0.9052 - val_accuracy: 0.5000\n","Epoch 76/100\n","1/1 [==============================] - 0s 47ms/step - loss: 0.5948 - accuracy: 0.6667 - val_loss: 0.9056 - val_accuracy: 0.5000\n","Epoch 77/100\n","1/1 [==============================] - 0s 46ms/step - loss: 0.7467 - accuracy: 0.3333 - val_loss: 0.9049 - val_accuracy: 0.5000\n","Epoch 78/100\n","1/1 [==============================] - 0s 52ms/step - loss: 1.3993 - accuracy: 0.3333 - val_loss: 0.9015 - val_accuracy: 0.5000\n","Epoch 79/100\n","1/1 [==============================] - 0s 48ms/step - loss: 0.5828 - accuracy: 0.6667 - val_loss: 0.9005 - val_accuracy: 0.5000\n","Epoch 80/100\n","1/1 [==============================] - 0s 47ms/step - loss: 0.6719 - accuracy: 1.0000 - val_loss: 0.9009 - val_accuracy: 0.5000\n","Epoch 81/100\n","1/1 [==============================] - 0s 52ms/step - loss: 0.7272 - accuracy: 0.6667 - val_loss: 0.9006 - val_accuracy: 0.5000\n","Epoch 82/100\n","1/1 [==============================] - 0s 48ms/step - loss: 0.4926 - accuracy: 1.0000 - val_loss: 0.8999 - val_accuracy: 0.5000\n","Epoch 83/100\n","1/1 [==============================] - 0s 46ms/step - loss: 1.0421 - accuracy: 0.3333 - val_loss: 0.8943 - val_accuracy: 0.5000\n","Epoch 84/100\n","1/1 [==============================] - 0s 49ms/step - loss: 0.6985 - accuracy: 0.6667 - val_loss: 0.8940 - val_accuracy: 0.5000\n","Epoch 85/100\n","1/1 [==============================] - 0s 47ms/step - loss: 0.4856 - accuracy: 1.0000 - val_loss: 0.8935 - val_accuracy: 0.5000\n","Epoch 86/100\n","1/1 [==============================] - 0s 45ms/step - loss: 0.7742 - accuracy: 0.3333 - val_loss: 0.8931 - val_accuracy: 0.5000\n","Epoch 87/100\n","1/1 [==============================] - 0s 52ms/step - loss: 0.5395 - accuracy: 1.0000 - val_loss: 0.8917 - val_accuracy: 0.5000\n","Epoch 88/100\n","1/1 [==============================] - 0s 51ms/step - loss: 0.8934 - accuracy: 0.6667 - val_loss: 0.8903 - val_accuracy: 0.5000\n","Epoch 89/100\n","1/1 [==============================] - 0s 46ms/step - loss: 0.9640 - accuracy: 0.6667 - val_loss: 0.8857 - val_accuracy: 0.5000\n","Epoch 90/100\n","1/1 [==============================] - 0s 40ms/step - loss: 0.5927 - accuracy: 0.6667 - val_loss: 0.8850 - val_accuracy: 0.5000\n","Epoch 91/100\n","1/1 [==============================] - 0s 43ms/step - loss: 0.7996 - accuracy: 0.3333 - val_loss: 0.8822 - val_accuracy: 0.5000\n","Epoch 92/100\n","1/1 [==============================] - 0s 45ms/step - loss: 0.7842 - accuracy: 0.3333 - val_loss: 0.8802 - val_accuracy: 0.5000\n","Epoch 93/100\n","1/1 [==============================] - 0s 50ms/step - loss: 0.7151 - accuracy: 0.6667 - val_loss: 0.8801 - val_accuracy: 0.5000\n","Epoch 94/100\n","1/1 [==============================] - 0s 50ms/step - loss: 0.9238 - accuracy: 0.6667 - val_loss: 0.8757 - val_accuracy: 0.5000\n","Epoch 95/100\n","1/1 [==============================] - 0s 50ms/step - loss: 0.9265 - accuracy: 0.6667 - val_loss: 0.8720 - val_accuracy: 0.5000\n","Epoch 96/100\n","1/1 [==============================] - 0s 49ms/step - loss: 1.2716 - accuracy: 0.0000e+00 - val_loss: 0.8696 - val_accuracy: 0.5000\n","Epoch 97/100\n","1/1 [==============================] - 0s 51ms/step - loss: 0.6185 - accuracy: 1.0000 - val_loss: 0.8699 - val_accuracy: 0.5000\n","Epoch 98/100\n","1/1 [==============================] - 0s 50ms/step - loss: 0.9137 - accuracy: 0.3333 - val_loss: 0.8675 - val_accuracy: 0.5000\n","Epoch 99/100\n","1/1 [==============================] - 0s 44ms/step - loss: 0.7489 - accuracy: 0.6667 - val_loss: 0.8657 - val_accuracy: 0.5000\n","Epoch 100/100\n","1/1 [==============================] - 0s 45ms/step - loss: 1.0018 - accuracy: 0.0000e+00 - val_loss: 0.8624 - val_accuracy: 0.5000\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f7dbcddf950>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l9c17s2mo289","executionInfo":{"status":"ok","timestamp":1617452321808,"user_tz":-300,"elapsed":5450,"user":{"displayName":"Aligohar Khokhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCbikLe5dCIFAg2TZGgZ4T1ynawIsMZqR168ZfXA=s64","userId":"18174892672448340788"}},"outputId":"b5de9ca5-a4e8-4752-c989-95d751547fa3"},"source":["loss, accuracy = model.evaluate(test_data, test_labels)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["1/1 [==============================] - 0s 15ms/step - loss: 0.8131 - accuracy: 0.6667\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VZ0s5Jaco28-","executionInfo":{"status":"ok","timestamp":1617452326103,"user_tz":-300,"elapsed":1186,"user":{"displayName":"Aligohar Khokhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCbikLe5dCIFAg2TZGgZ4T1ynawIsMZqR168ZfXA=s64","userId":"18174892672448340788"}},"outputId":"2ccd538e-84d3-4a40-9cf5-9ba674cb38ec"},"source":["loss"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8130545020103455"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V8rzRhSLo28-","executionInfo":{"status":"ok","timestamp":1617452328035,"user_tz":-300,"elapsed":1206,"user":{"displayName":"Aligohar Khokhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCbikLe5dCIFAg2TZGgZ4T1ynawIsMZqR168ZfXA=s64","userId":"18174892672448340788"}},"outputId":"4ea870d3-6f96-4d71-b189-32c9a80f8ab0"},"source":["accuracy"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6666666865348816"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HaO0uUB7o29A","executionInfo":{"status":"ok","timestamp":1617452365930,"user_tz":-300,"elapsed":801,"user":{"displayName":"Aligohar Khokhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCbikLe5dCIFAg2TZGgZ4T1ynawIsMZqR168ZfXA=s64","userId":"18174892672448340788"}},"outputId":"db91a442-94d5-4cb0-fbf6-cadcd7995fa0"},"source":["x = model.predict(test_data).astype(dtype=\"u8\")\n","a=x\n","b= np.array(test_labels)\n","a= a.reshape(1,a.shape[0])\n","np.size(a != b) - np.count_nonzero(a == b)"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IXBnHx8vo29D","executionInfo":{"status":"ok","timestamp":1617452560608,"user_tz":-300,"elapsed":765,"user":{"displayName":"Aligohar Khokhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCbikLe5dCIFAg2TZGgZ4T1ynawIsMZqR168ZfXA=s64","userId":"18174892672448340788"}},"outputId":"0eba5c6a-8870-4e03-fd7e-4447ef6f433d"},"source":["con = tf.math.confusion_matrix(labels= test_labels, predictions=x )\n","con"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n","array([[2, 0],\n","       [1, 0]], dtype=int32)>"]},"metadata":{"tags":[]},"execution_count":31}]}]}